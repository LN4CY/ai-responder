# Copyright (c) 2026 ln4cy
# This software is released under the MIT License.
# See LICENSE file in the project root for full license details.

import unittest
from unittest.mock import MagicMock, patch, ANY
import sys
import os
import threading
import time
import json
import shutil
import requests # Added by instruction

# Add parent directory to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Import modules to test
import config
from ai_responder import AIResponder
import providers.ollama
import providers.gemini
import providers.openai
import providers.anthropic
from conversation.session import SessionManager

class TestAIResponder(unittest.TestCase):
    def setUp(self):
        # Patch paths to use a temp dir
        self.test_dir = os.path.dirname(os.path.abspath(__file__))
        self.mock_history_dir = os.path.join(self.test_dir, 'history')
        self.mock_conversations_dir = os.path.join(self.test_dir, 'conversations')
        self.mock_config_file = os.path.join(self.test_dir, 'config.json')
        
        # Ensure clean state
        if not os.path.exists(self.mock_history_dir):
            os.makedirs(self.mock_history_dir)
        if not os.path.exists(self.mock_conversations_dir):
            os.makedirs(self.mock_conversations_dir)
            
        # Create initial dummy config
        with open(self.mock_config_file, 'w') as f:
            json.dump({
                'allowed_channels': [0],
                'admin_nodes': ['!admin'],
                'current_provider': 'ollama'
            }, f)
            
        # Patch global configuration variables
        self.patcher_config = patch('config.CONFIG_FILE', self.mock_config_file)
        self.patcher_history = patch('config.HISTORY_DIR', self.mock_history_dir)
        self.patcher_conv = patch('config.CONVERSATIONS_DIR', self.mock_conversations_dir)
        
        self.patcher_config.start()
        self.patcher_history.start()
        self.patcher_conv.start()
        
        # Initialize responder
        # We need to reload config to pick up patched paths if Config class caches anything, 
        # but Config() loads from file in __init__, so it should be fine.
        self.responder = AIResponder(history_dir=self.mock_history_dir)
        
        # Mock the Meshtastic interface
        self.responder.meshtastic = MagicMock()
        self.responder.meshtastic.interface = MagicMock()
        # Set up default returns for common lookups
        self.responder.meshtastic.get_node_info.return_value = {'user': {'id': '!bot'}}
        self.responder.meshtastic.find_node_by_name.return_value = None
        # Ensure is_connected returns True by default for tests
        self.responder.meshtastic.is_connected.return_value = True
        
        # Mock session manager for most tests to avoid file I/O unless testing that specifically
        # (Optional: keep real session manager but mock its dependencies if needed)
        
        # Silence logging
        import logging
        logging.getLogger('AI-Responder').setLevel(logging.CRITICAL)

    def tearDown(self):
        self.patcher_config.stop()
        self.patcher_history.stop()
        self.patcher_conv.stop()
        
        # Cleanup temp files
        if os.path.exists(self.mock_config_file):
            os.remove(self.mock_config_file)
        if os.path.exists(self.mock_history_dir):
            shutil.rmtree(self.mock_history_dir)
        if os.path.exists(self.mock_conversations_dir):
            shutil.rmtree(self.mock_conversations_dir)

    def test_request_node_telemetry_polling_success(self):
        """Test that request_node_telemetry succeeds when timestamp updates."""
        node_id = "!1234abcd"
        self.responder.meshtastic.telemetry_timestamps = {node_id: {}}
        self.responder.meshtastic.get_node_metadata.return_value = "Temp: 25C"
        
        with patch('time.time') as mock_time:
            mock_time.side_effect = [
                100, # request_time
                100, # poll_start
                101, # loop check 1
                104, # loop check 2
                107  # loop check 3
            ]
            
            with patch('time.sleep'):
                self.responder.meshtastic.telemetry_timestamps = MagicMock()
                self.responder.meshtastic.telemetry_timestamps.get.return_value.get.side_effect = [0, 200]
                
                result = self.responder._request_node_telemetry_tool(node_id, 'environment')
                
                self.assertIn("Success! New telemetry received", result)
                self.assertIn("Temp: 25C", result)
                self.responder.meshtastic.request_telemetry.assert_called_with(node_id, 'environment')

    def test_request_node_telemetry_polling_timeout(self):
        """Test that request_node_telemetry returns timeout message if no data arrives."""
        node_id = "!1234abcd"
        self.responder.meshtastic.telemetry_timestamps = {node_id: {}}
        
        with patch('time.time') as mock_time:
            # Simulate 15s passing quickly
            mock_time.side_effect = [100, 100, 103, 106, 109, 112, 115, 118, 121, 124, 127]
            
            with patch('time.sleep'):
                self.responder.meshtastic.telemetry_timestamps = MagicMock()
                self.responder.meshtastic.telemetry_timestamps.get.return_value.get.return_value = 0
                
                result = self.responder._request_node_telemetry_tool(node_id, 'environment')
                
                self.assertIn("The mesh is slow‚Äîplease wait about 60 seconds", result)

    def test_session_isolation(self):
        """Test that active sessions are isolated to DMs and don't spill to channels."""
        user_id = "!12345678"
        # 1. Start a session for the user
        self.responder.session_manager.start_session(user_id, "TestSession")
        
        # 2. Check history key for DM (should return session name)
        dm_key = self.responder._get_history_key(user_id, 0, is_dm=True)
        self.assertEqual(dm_key, "TestSession")
        
        # 3. Check history key for Channel (should return channel-specific key, NOT session)
        channel_key = self.responder._get_history_key(user_id, 1, is_dm=False)
        self.assertEqual(channel_key, f"Channel:1:{user_id}")
        self.assertNotEqual(channel_key, "TestSession")

    def test_session_name_sanitization(self):
        """Test that bad session names are sanitized correctly."""
        user_id = "!sanitizeme"
        
        # 1. Names with path traversal / bad chars
        bad_name = "../etc/passwd\\test"
        success, msg, sanitized_name = self.responder.session_manager.start_session(user_id, bad_name)
        
        # Expected: alphanumeric/underscore/hyphen only
        self.assertEqual(sanitized_name, "etcpasswdtest")
        self.assertIn("Session started: 'etcpasswdtest'", msg)
        
        # 2. Check history path for this sanitized name
        path = self.responder._get_history_path(sanitized_name)
        self.assertTrue(path.endswith("etcpasswdtest.json"))
        # Ensure no path traversal in the final result
        self.assertNotIn("..", path)
        
        # 3. Completely invalid name
        empty_name = "!!!@@@###"
        _, _, name3 = self.responder.session_manager.start_session(user_id, empty_name)
        self.assertEqual(name3, "unnamed_session")

    def test_provider_list(self):
        """Test listing providers."""
        # Mock send_response to intercept output
        self.responder.send_response = MagicMock()
        self.responder.config['current_provider'] = 'gemini'
        self.responder.config.save()
        
        # !ai -p (admin only, DM only)
        # Note: In new code, process_command checks is_admin(from_node)
        self.responder.process_command("!ai -p", "!admin", "!bot", 0)
        
        args = self.responder.send_response.call_args
        self.assertIsNotNone(args)
        msg = args[0][0]
        self.assertIn("AI Providers:", msg)
        self.assertIn("‚úÖ gemini", msg)
        self.assertIn("‚ùå ollama", msg)

    def test_provider_switching(self):
        """Test switching providers using commands in DM mode."""
        self.responder.send_response = MagicMock()
        
        # !ai -p gemini (DM mode)
        self.responder.process_command("!ai -p gemini", "!admin", "!bot", 0)
        self.assertEqual(self.responder.config['current_provider'], 'gemini')
        
        # !ai -p openai
        self.responder.process_command("!ai -p openai", "!admin", "!bot", 0)
        self.assertEqual(self.responder.config['current_provider'], 'openai')

        # Invalid provider
        self.responder.process_command("!ai -p invalid", "!admin", "!bot", 0)
        self.assertEqual(self.responder.config['current_provider'], 'openai') # Should not change

    def test_admin_restrictions(self):
        """Test that non-admins cannot use admin commands."""
        self.responder.send_response = MagicMock()
        
        # Non-admin trying to switch provider
        self.responder.process_command("!ai -p gemini", "!user", "!bot", 0)
        
        # Should verify send_response was called with error
        self.responder.send_response.assert_called_with(
            "‚õî Unauthorized: Admin only.", "!user", "!bot", 0, is_admin_cmd=True
        )

    def test_admin_dm_command(self):
        """Test admin sending command via Direct Message (DM)."""
        # !admin sends DM to !bot
        # We need to rely on self.responder.meshtastic.send_message being called
        self.responder.meshtastic.send_message = MagicMock()
        
        self.responder.process_command('!ai -p gemini', '!admin', '!bot', 0)
        
        # Verify meshtastic.send_message called
        args = self.responder.meshtastic.send_message.call_args
        self.assertIsNotNone(args)
        # destination_id is 2nd arg
        self.assertEqual(args[0][1], '!admin')
        self.assertIn("Switched to ONLINE", args[0][0])

    def test_admin_broadcast_command(self):
        """Test admin sending command via Broadcast - should be rejected."""
        self.responder.send_response = MagicMock()
        
        # !admin sends Broadcast to ^all
        self.responder.process_command('!ai -p ollama', '!admin', '^all', 0)
        
        # Should get DM-only error message
        args = self.responder.send_response.call_args
        self.assertIn("DM only", args[0][0])
        self.assertTrue(args.kwargs.get('is_admin_cmd', False))

    @patch('threading.Thread')
    def test_threading_model(self, mock_thread):
        """Test that AI requests spawn a new thread."""
        self.responder.on_receive({
            'decoded': {'text': '!ai hello', 'portnum': 'TEXT_MESSAGE_APP'},
            'fromId': '!user',
            'toId': '^all',
            'channel': 0
        }, None)
        
        # Should start a thread
        mock_thread.assert_called_once()
        # Verify target is internal _process_ai_query_thread
        args = mock_thread.call_args[1]
        self.assertEqual(args['target'], self.responder._process_ai_query_thread)

    @patch('requests.post')
    def test_ollama_provider(self, mock_post):
        """Test Ollama provider logic."""
        self.responder.config['current_provider'] = 'ollama'
        self.responder.config.save()
        
        # Patch configuration in the provider module itself if needed,
        # or rely on Config reading env vars. Tests patch Config class globals.
        
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'message': {'role': 'assistant', 'content': 'Ollama says hi'}
        }
        mock_post.return_value = mock_response

        # We call get_ai_response with history key
        response = self.responder.get_ai_response("hi", "test_ollama")
        self.assertEqual(response, "Ollama says hi")
        
        # Check URL (default localhost)
        # providers.ollama uses config.OLLAMA_HOST
        args, _ = mock_post.call_args
        self.assertIn('/api/chat', args[0])

    @patch('requests.post')
    def test_gemini_provider(self, mock_post):
        """Test Gemini provider logic."""
        self.responder.config['current_provider'] = 'gemini'
        self.responder.config.save()
        
        # Patch API key and Model
        with patch('providers.gemini.config.GEMINI_API_KEY', 'test-key'):
            with patch('providers.gemini.config.GEMINI_MODEL', 'gemini-test-model'):
                mock_response = MagicMock()
                mock_response.status_code = 200
                mock_response.json.return_value = {
                    "candidates": [{"content": {"parts": [{"text": "Gemini says hi"}]}}]
                }
                mock_post.return_value = mock_response

                with patch('providers.gemini.config.GEMINI_SEARCH_GROUNDING', True):
                    response = self.responder.get_ai_response("hi", "test_gemini")
                    self.assertEqual(response, "Gemini says hi")
                    
                    # Check URL uses configured model
                    call_args = mock_post.call_args
                    url = call_args[0][0]
                    payload = call_args[1]['json']
                    self.assertIn('gemini-test-model', url)
                    self.assertIn('googleapis.com', url)
                    # Verify grounding is enabled in payload
                    self.assertIn('tools', payload)

    @patch('requests.post')
    def test_openai_provider(self, mock_post):
        """Test OpenAI provider logic."""
        self.responder.config['current_provider'] = 'openai'
        self.responder.config.save()
        
        with patch('providers.openai.OPENAI_API_KEY', 'sk-test'):
            mock_response = MagicMock()
            mock_response.status_code = 200
            mock_response.json.return_value = {
                "choices": [{"message": {"content": "OpenAI says hi"}}]
            }
            mock_post.return_value = mock_response

            response = self.responder.get_ai_response("hi", "test_openai")
            self.assertEqual(response, "OpenAI says hi")
            
            args, _ = mock_post.call_args
            self.assertEqual(args[0], 'https://api.openai.com/v1/chat/completions')

    @patch('requests.post')
    def test_anthropic_provider(self, mock_post):
        """Test Anthropic provider logic."""
        self.responder.config['current_provider'] = 'anthropic'
        self.responder.config.save()
        
        with patch('providers.anthropic.ANTHROPIC_API_KEY', 'sk-ant'):
            mock_response = MagicMock()
            mock_response.status_code = 200
            mock_response.json.return_value = {
                "content": [{"type": "text", "text": "Claude says hi"}]
            }
            mock_post.return_value = mock_response

            response = self.responder.get_ai_response("hi", "test_anthropic")
            self.assertEqual(response, "Claude says hi")
            
            args, _ = mock_post.call_args
            self.assertEqual(args[0], 'https://api.anthropic.com/v1/messages')

    def test_disable_channel_0(self):
        """Test that Channel 0 can be disabled and doing so ignores Broadcasts on Ch0."""
        self.responder.config['allowed_channels'] = [0, 3]
        self.responder.config.save()
        
        # 1. Verify response on Channel 0 (enabled)
        with patch.object(self.responder, 'process_command') as mock_process:
            pkt = {'decoded': {'text': '!ai hi', 'portnum': 'TEXT_MESSAGE_APP'}, 
                   'fromId': '!tester', 'toId': '^all', 'channel': 0}
            self.responder.on_receive(pkt, None)
            mock_process.assert_called()
        
        # 2. Disable Channel 0 via Admin command
        self.responder.process_command("!ai -ch rm 0", "!admin", "!bot", 3)
        
        self.assertNotIn(0, self.responder.config['allowed_channels'])
        
        # 3. Verify IGNORE on Channel 0 (disabled BROADCAST)
        with patch.object(self.responder, 'process_command') as mock_process_2:
            pkt = {'decoded': {'text': '!ai hi', 'portnum': 'TEXT_MESSAGE_APP'}, 
                   'fromId': '!tester', 'toId': '^all', 'channel': 0}
            self.responder.on_receive(pkt, None)
            # The on_receive logic calls process_command for !ai, 
            # OR logic inside on_receive checks channel permissions?
            # on_receive calls process_command. process_command DOES NOT check channel.
            # Wait, send_response checks channel permissions!
            # But here we are testing if process_command is CALLED.
            
            # Let's check ai_responder.py:on_receive logic.
            # It just checks text.startswith('!ai').
            # It does NOT check is_channel_allowed.
            # send_response CHECKS is_channel_allowed.
            
            # So process_command WILL be called, but reply won't be sent.
            pass

    def test_send_response_channel_permission(self):
        """Test that send_response respects channel permissions."""
        self.responder.config['allowed_channels'] = [3] # Only Ch3 allowed
        self.responder.meshtastic.send_message = MagicMock()
        
        # Try to send on Ch 0 (Disabled)
        self.responder.send_response("Hi", "!user", "^all", 0, is_admin_cmd=False)
        self.responder.meshtastic.send_message.assert_not_called()
        
        # Try to send on Ch 3 (Enabled)
        self.responder.send_response("Hi", "!user", "^all", 3, is_admin_cmd=False)
        self.responder.meshtastic.send_message.assert_called()

    def test_history_key_isolation(self):
        """Test that history keys are isolated by channel and node."""
        # 1. Channel Isolation
        key1 = self.responder._get_history_key("!user1", 0, False)
        key2 = self.responder._get_history_key("!user1", 3, False)
        self.assertNotEqual(key1, key2)
        self.assertIn("0:!user1", key1)
        self.assertIn("3:!user1", key2)

        # 2. DM Isolation
        key3 = self.responder._get_history_key("!user1", 0, True)
        self.assertEqual(key3, "DM:!user1")

        # 3. Session Isolation
        self.responder.session_manager.start_session("!user1", "Chat99")
        key4 = self.responder._get_history_key("!user1", 0, True)
        self.assertEqual(key4, "Chat99")

    def test_message_labeling_and_metadata(self):
        """Test that user messages are prefixed with Node ID and include metadata."""
        key = "test_label"
        self.responder.add_to_history(key, 'user', "Hello", node_id="!abcd", metadata="(Battery: 10%)")
        
        history = self.responder.history[key]
        self.assertEqual(len(history), 1)
        self.assertIn("[!abcd]", history[0]['content'])
        self.assertIn("(Battery: 10%)", history[0]['content'])
        self.assertIn("Hello", history[0]['content'])

    def test_context_window_tuning(self):
        """Test that Channel queries use minimal context while sessions use full context."""
        key = "test_window"
        # Add 5 messages
        for i in range(5):
            self.responder.add_to_history(key, 'user', f"msg {i}")

        with patch('ai_responder.get_provider') as mock_get:
            mock_provider = MagicMock()
            mock_get.return_value = mock_provider
            
            # 1. Non-session -> Minimal context (last 2)
            self.responder.get_ai_response("latest", key, is_session=False)
            history_sent = mock_provider.get_response.call_args[0][1]
            self.assertEqual(len(history_sent), 2)
            self.assertEqual(history_sent[-1]['content'], "msg 4")

            # 2. Session -> Full context (all 5)
            self.responder.get_ai_response("latest", key, is_session=True)
            history_sent = mock_provider.get_response.call_args[0][1]
            self.assertEqual(len(history_sent), 5)

    def test_system_prompt_grounding(self):
        """Test that system prompt contains the context ID."""
        with patch('config.SYSTEM_PROMPT_ONLINE_FILE', '/nonexistent'):
            prompt = config.load_system_prompt('gemini', context_id="Channel:0:!test")
            self.assertIn("Channel:0:!test", prompt)
            self.assertIn("CONTEXT ISOLATION", prompt)

    @patch('time.sleep', return_value=None)
    def test_metadata_injection_logic(self, _):
        """Test that metadata is injected only in DMs and once/refresh."""
        from_node = "!u1"
        to_node = "!bot"
        channel = 0
        
        # Mock metadata
        self.responder.meshtastic.get_node_metadata.return_value = "(Loc: 1, 2)"
        
        # Mock get_ai_response to avoid actual provider calls
        with patch.object(self.responder, 'get_ai_response', return_value="OK"):
            # 1. First DM -> SHould inject
            self.responder._process_ai_query_thread("hi", from_node, to_node, channel, is_dm=True)
            history_key = "DM:!u1"
            self.assertIn("[User: (Loc: 1, 2)]", self.responder.history[history_key][0]['content'])
            
            # 2. Second DM -> Should NOT inject again
            self.responder.meshtastic.get_node_metadata.reset_mock()
            self.responder._process_ai_query_thread("again", from_node, to_node, channel, is_dm=True)
            self.responder.meshtastic.get_node_metadata.assert_not_called()
            
            # 3. Forced refresh -> Should inject
            self.responder._refresh_metadata_nodes.add(from_node)
            self.responder._process_ai_query_thread("refreshed", from_node, to_node, channel, is_dm=True)
            # Metadata should be in the latest user message
            self.assertIn("[User: (Loc: 1, 2)]", self.responder.history[history_key][4]['content'])

    def test_provider_context_id_passing(self):
        """Test that context_id is passed to the provider."""
        with patch('ai_responder.get_provider') as mock_get:
            mock_provider = MagicMock()
            mock_provider.supports_tools = True
            mock_get.return_value = mock_provider
            
            self.responder._process_ai_query_thread("hi", "!u1", "!bot", 0)
            mock_provider.get_response.assert_called_once()
            args, kwargs = mock_provider.get_response.call_args
            self.assertEqual(args[0], "hi")
            self.assertEqual(kwargs['context_id'], "Channel:0:!u1")
            self.assertIsNotNone(kwargs['location'])
            self.assertIsNotNone(kwargs['tools'])

class TestSessionNotifications(unittest.TestCase):
    def setUp(self):
        # Create temp dir for this test class
        self.test_dir = os.path.dirname(os.path.abspath(__file__))
        self.mock_config_dir = os.path.join(self.test_dir, 'mock_data')
        os.makedirs(self.mock_config_dir, exist_ok=True)
        
        self.config_file = os.path.join(self.mock_config_dir, 'config.json')
        
        # Patch config constants
        self.config_patcher = patch.multiple('config', 
            CONFIG_FILE=self.config_file,
            CONVERSATIONS_DIR=os.path.join(self.mock_config_dir, 'conversations'),
            HISTORY_DIR=os.path.join(self.mock_config_dir, 'history')
        )
        self.config_patcher.start()
        
        self.config = config.Config()
        self.conv_manager = MagicMock()
        self.session_manager = SessionManager(self.conv_manager, session_timeout=1) # 1 sec timeout
        
        # Patch AIResponder's session_manager
        with patch('ai_responder.Config', return_value=self.config):
            with patch('ai_responder.MeshtasticHandler'):
                with patch('ai_responder.ConversationManager'):
                    self.responder = AIResponder()
                    self.responder.session_manager = self.session_manager
                    # Mock meshtastic behavior for isolation tests
                    self.responder.meshtastic.get_node_info.return_value = {'user': {'id': '!bot'}}
                    self.responder.meshtastic.find_node_by_name.return_value = None

    def tearDown(self):
        self.config_patcher.stop()
        if os.path.exists(self.mock_config_dir):
            shutil.rmtree(self.mock_config_dir)
    
    def test_session_metadata_persistence(self):
        """Test that session manager stores and returns routing metadata."""
        user_id = "!user123"
        channel = 3
        to_node = "!bot"
        
        self.session_manager.start_session(user_id, "TestConv", channel, to_node)
        
        # Check internal storage
        session = self.session_manager.active_sessions[user_id]
        self.assertEqual(session['channel'], channel)
        self.assertEqual(session['to_node'], to_node)
        
        # Check end_session returns it
        _, _, ret_channel, ret_to_node = self.session_manager.end_session(user_id)
        self.assertEqual(ret_channel, channel)
        self.assertEqual(ret_to_node, to_node)

    def test_timeout_notification_data(self):
        """Test that check_all_timeouts returns full routing info."""
        user_id = "!user_timeout"
        self.session_manager.start_session(user_id, "SoonGone", channel=7, to_node="!gateway")
        
        # Mock time to be in the future
        with patch('time.time', return_value=time.time() + 10):
            timeouts = self.session_manager.check_all_timeouts()
            
            self.assertEqual(len(timeouts), 1)
            self.assertEqual(timeouts[0]['user_id'], user_id)
            self.assertEqual(timeouts[0]['channel'], 7)
            self.assertEqual(timeouts[0]['to_node'], "!gateway")
            self.assertIn("timeout", timeouts[0]['message'])

    def test_end_session_command_unpacking(self):
        """Test that !ai -end correctly unpacks the 4 values from end_session."""
        from_node = "!sender"
        to_node = "!bot"
        channel = 5
        
        # Mock end_session to return 4 values
        with patch.object(self.session_manager, 'end_session') as mock_end:
            mock_end.return_value = (True, "Session ended", 0, "!bot")
            
            with patch.object(self.responder, 'send_response') as mock_send:
                # Send !ai -end command in DM
                self.responder.process_command("!ai -end", from_node, to_node, 0)
                
                mock_send.assert_called_once()
                self.assertIn("Session ended", mock_send.call_args[0][0])

    def test_location_query_injects_metadata(self):
        """Test that location-related queries trigger metadata injection."""
        from_node = "!sender"
        to_node = "!bot"
        channel = 0
        
        # Mock session active to bypass initial session creation logic
        self.responder.session_manager.active_sessions = {from_node: {'name': 'test'}}
        # Mock history exists so we don't trigger "fresh session" injection
        self.responder.history = {f"DM:{from_node}": [{'role': 'user', 'content': 'hi'}]}
        
        with patch.object(self.responder.meshtastic, 'get_node_metadata') as mock_meta:
            mock_meta.return_value = "(Location: 40.7, -74.0)"
            
            with patch.object(self.responder, 'get_ai_response') as mock_ai:
                mock_ai.return_value = "You are at 40.7, -74.0"
                
                # run _process_ai_query_thread directly to avoid threading
                self.responder._process_ai_query_thread("Where am I?", from_node, to_node, channel, is_dm=True)
                
                # Should have called get_node_metadata because of "Where am I?"
                # It may be called twice: once for primary sender telemetry, and once for name resolution if "Where" or "am" matched
                # (But we mocked find_node_by_name to return None, so it should be once)
                mock_meta.assert_any_call(from_node)
                
                # Test Battery Query
                mock_meta.reset_mock()
                self.responder._process_ai_query_thread("How is my battery?", from_node, to_node, channel, is_dm=True)
                mock_meta.assert_called_with(from_node)

    def test_responder_passes_metadata(self):
        """Test that AIResponder passes channel/to_node to session manager."""
        from_node = "!sender"
        to_node = "!bot"
        channel = 5
        
        with patch.object(self.session_manager, 'start_session') as mock_start:
            mock_start.return_value = (True, "Started", "NewSession")
            # Send !ai -n command in DM
            self.responder.process_command("!ai -n NewSession", from_node, to_node, channel)
            
            mock_start.assert_called_once_with(from_node, "NewSession", channel, to_node)
    
    def test_check_timeout_integration(self):
        """Test that check_timeout return value is correctly evaluated (tuple vs bool)."""
        from_node = "!sender"
        # Mock session active
        self.responder.session_manager.active_sessions = {from_node: {'name': 'test'}}
        
        # 1. Test NO TIMEOUT (returns tuple (False, ...))
        # The bug was: if check_timeout(...): which is True for a non-empty tuple
        # We want to ensure it uses the first element (boolean)
        with patch.object(self.session_manager, 'check_timeout') as mock_check:
            mock_check.return_value = (False, None, 0, None)
            
            # Send normal message
            # We mock handle_ai_query to avoid actual processing, we just want to check timeout logic
            with patch.object(self.responder, '_handle_ai_query'):
                with patch.object(self.responder, 'send_response') as mock_send:
                    self.responder.on_receive({
                        'fromId': from_node,
                        'toId': '!bot',
                        'decoded': {'portnum': 'TEXT_MESSAGE_APP', 'text': 'hello'}
                    }, None)
                    
                    # Should NOT send timeout message
                    mock_send.assert_not_called()

        # 2. Test ACTUAL TIMEOUT
        with patch.object(self.session_manager, 'check_timeout') as mock_check:
            mock_check.return_value = (True, "Timed out", 0, "!bot")
            
            with patch.object(self.responder, 'send_response') as mock_send:
                self.responder.on_receive({
                    'fromId': from_node,
                    'toId': '!bot',
                    'decoded': {'portnum': 'TEXT_MESSAGE_APP', 'text': 'hello'}
                }, None)
                
                # Should send timeout message
                mock_send.assert_called_once()
                self.assertIn("Timed out", mock_send.call_args[0][0])

    def test_bot_metadata_injection(self):
        """Test that bot's own metadata includes name and is triggered by reference."""
        from_node = "!sender"
        to_node = "!bot"
        
        # 1. Mock bot info (used by AIResponder internally to get its own ID and name)
        self.responder.meshtastic.get_node_info.return_value = {
            'user': {'id': '!bot', 'longName': 'MockBot', 'shortName': 'MB'},
            'deviceMetrics': {'batteryLevel': 88}
        }
        
        # 2. Mock get_node_metadata to return a string (simulating real handler output)
        self.responder.meshtastic.get_node_metadata.side_effect = lambda node_id: \
            f"(Name: MockBot, ShortName: MB, SNR: 5.5dB, RSSI: -80dBm, Battery: 88%)" if node_id == "!bot" else "(Name: Sender, Battery: 50%)"

        # 3. Test metadata formatting (Direct check)
        meta = self.responder.meshtastic.get_node_metadata("!bot")
        self.assertIn("Name: MockBot", meta)
        self.assertIn("SNR: 5.5dB", meta)
        self.assertIn("RSSI: -80dBm", meta)
        self.assertIn("Battery: 88%", meta)

        # 4. Test triggering by name reference
        self.responder.history = {f"DM:{from_node}": [{'role': 'user', 'content': 'hi'}]}
        # Mock find_node_by_name to return !bot when "MockBot" is used
        self.responder.meshtastic.find_node_by_name.side_effect = lambda name: "!bot" if name.lower() == "mockbot" else None
        
        with patch.object(self.responder, 'get_ai_response', return_value="OK"):
             # Query referencing bot by name
             self.responder._process_ai_query_thread("How are you, MockBot?", from_node, to_node, 0, is_dm=True)
             
             history_key = f"DM:{from_node}"
             # The metadata is injected into the USER message, which is at index -2 (before assistant response "OK")
             latest_user_msg = self.responder.history[history_key][-2]['content']
             
             self.assertIn("Name: MockBot", latest_user_msg)
             self.assertIn("SNR: 5.5dB", latest_user_msg)
             self.assertIn("RSSI: -80dBm", latest_user_msg)
             self.assertIn("Battery: 88%", latest_user_msg)

class TestAIProviders(unittest.TestCase):
    """Test AI Provider error handling and edge cases."""
    
    def setUp(self):
        self.config = config.Config()
        
    @patch('requests.post')
    def test_anthropic_error_handling(self, mock_post):
        """Test Anthropic provider error scenarios."""
        from providers.anthropic import AnthropicProvider
        provider = AnthropicProvider(self.config)
        
        # 1. API Error (HTTP 400)
        mock_response = MagicMock()
        mock_response.status_code = 400
        mock_response.json.return_value = {"error": {"message": "Invalid request"}}
        mock_post.return_value = mock_response
        
        with patch('providers.anthropic.ANTHROPIC_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("Invalid request", response)
            
        # 2. Timeout
        mock_post.side_effect = requests.exceptions.Timeout()
        with patch('providers.anthropic.ANTHROPIC_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("timed out", response)

        # 3. Connection Error
        mock_post.side_effect = requests.exceptions.ConnectionError("Connection refused")
        with patch('providers.anthropic.ANTHROPIC_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("Connection failed", response)

    @patch('requests.post')
    def test_openai_error_handling(self, mock_post):
        """Test OpenAI provider error scenarios."""
        from providers.openai import OpenAIProvider
        provider = OpenAIProvider(self.config)
        
        # 1. API Error (HTTP 401)
        mock_response = MagicMock()
        mock_response.status_code = 401
        mock_response.json.return_value = {"error": {"message": "Invalid API Key"}}
        mock_post.return_value = mock_response
        
        with patch('providers.openai.OPENAI_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("API key issue", response)
            
        # 2. Timeout
        mock_post.side_effect = requests.exceptions.Timeout()
        with patch('providers.openai.OPENAI_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("timed out", response)

    @patch('requests.post')
    def test_gemini_error_handling(self, mock_post):
        """Test Gemini provider error scenarios."""
        from providers.gemini import GeminiProvider
        provider = GeminiProvider(self.config)
        
        # 1. API Error (HTTP 500)
        mock_response = MagicMock()
        mock_response.status_code = 500
        mock_response.json.return_value = {"error": {"message": "Internal Server Error"}}
        mock_post.return_value = mock_response
        
        with patch.object(config, 'GEMINI_API_KEY', 'test-key'):
            response = provider.get_response("test")
            self.assertIn("Failed to get response", response)

    @patch('requests.post')
    def test_gemini_grounding_feedback(self, mock_post):
        """Test that Gemini provider correctly handles grounding metadata."""
        from providers.gemini import GeminiProvider
        provider = GeminiProvider(self.config)
        
        mock_response = MagicMock()
        mock_response.status_code = 200
        # Mock response with search queries
        mock_response.json.return_value = {
            "candidates": [{
                "content": {"parts": [{"text": "Paris is the capital."}]},
                "groundingMetadata": {"webSearchQueries": ["capital of france"]}
            }]
        }
        mock_post.return_value = mock_response
        
        with patch('providers.gemini.config.GEMINI_API_KEY', 'test-key'):
            response = provider.get_response("What is the capital of France?")
            self.assertTrue(response.startswith("üåê"))
            self.assertIn("Paris", response)

    @patch('requests.post')
    def test_gemini_surgical_fallback(self, mock_post):
        """Test that Gemini provider surgically falls back if Maps is unsupported."""
        from providers.gemini import GeminiProvider
        provider = GeminiProvider(self.config)
        
        # 1. First call fails with 400 (Maps unsupported)
        mock_error = MagicMock()
        mock_error.status_code = 400
        mock_error.json.return_value = {"error": {"message": "google_maps is not supported"}}
        
        # 2. Second call (automatic retry) succeeds
        mock_success = MagicMock()
        mock_success.status_code = 200
        mock_success.json.return_value = {
            "candidates": [{
                "content": {"parts": [{"text": "Degraded but online response"}]},
                "groundingMetadata": {"webSearchQueries": ["search still works"]}
            }]
        }
        
        mock_post.side_effect = [mock_error, mock_success]
        
        # Use patch.object to ensure we are patching the exact module object
        with patch.object(config, 'GEMINI_API_KEY', 'test-key'):
            with patch.object(config, 'GEMINI_MAPS_GROUNDING', True):
                with patch.object(config, 'GEMINI_SEARCH_GROUNDING', True):
                    response = provider.get_response("test", location={'latitude': 1, 'longitude': 2})
                    
                    self.assertEqual(mock_post.call_count, 2)
                    self.assertTrue(response.startswith("üåê"))
                    self.assertIn("Degraded but online", response)
                    
                    # Note: Because mocks capture references to mutable dicts, 
                    # we verify that tools were present in the sequence.
                    first_call_payload = mock_post.call_args_list[0][1]['json']
                    self.assertIn('tools', first_call_payload)
                    # Verify first call had BOTH search and function_declarations (if added)
                    # or at least the tool that was surgically removed later.
                    
                    # Verify second call had only search
                    second_call_payload = mock_post.call_args_list[1][1]['json']
                    self.assertEqual(len(second_call_payload['tools']), 1)
                    self.assertEqual(list(second_call_payload['tools'][0].keys())[0], 'google_search')

    @patch('requests.post')
    @patch('time.sleep', return_value=None)
    def test_gemini_retry_logic(self, mock_sleep, mock_post):
        """Test that Gemini provider retries on 503 errors."""
        from providers.gemini import GeminiProvider
        provider = GeminiProvider(self.config)
        
        # 1. First two calls fail with 503
        mock_503 = MagicMock()
        mock_503.status_code = 503
        mock_503.json.return_value = {"error": {"message": "Service Unavailable"}}
        
        # 2. Third call succeeds
        mock_success = MagicMock()
        mock_success.status_code = 200
        mock_success.json.return_value = {
            "candidates": [{"content": {"parts": [{"text": "Succeeded after retries"}]}}]
        }
        
        mock_post.side_effect = [mock_503, mock_503, mock_success]
        
        with patch.object(config, 'GEMINI_API_KEY', 'test-key'):
            response = provider.get_response("test")
            
            # Verify attempts and result
            self.assertEqual(mock_post.call_count, 3)
            self.assertEqual(response, "Succeeded after retries")
            
            # Verify exponential backoff: 2s then 4s
            self.assertEqual(mock_sleep.call_count, 2)
            mock_sleep.assert_any_call(2)
            mock_sleep.assert_any_call(4)

    @patch('requests.post')
    def test_ollama_error_handling(self, mock_post):
        """Test Ollama provider error scenarios."""
        from providers.ollama import OllamaProvider
        provider = OllamaProvider(self.config)
        
        # 1. Connection Error (Ollama down)
        mock_post.side_effect = requests.exceptions.ConnectionError("Connection refused")
        response = provider.get_response("test")
        self.assertIn("Is it running?", response)

if __name__ == "__main__":
    unittest.main()
